{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1(a) - Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ac429d692d43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munder_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomUnderSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomOverSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import stats\n",
    "\n",
    "data = pd.read_csv('./tesco_17357376.csv')\n",
    "\n",
    "data.pop('area_id')\n",
    "\n",
    "# remove h_n, _std, _norm_ _ci95\n",
    "suffix_of_col_to_remove = ['h_n','_std','_norm','_ci95']\n",
    "cols_to_remove = set()\n",
    "for col in data.columns:\n",
    "    for suffix in suffix_of_col_to_remove:\n",
    "        if suffix in col and col not in cols_to_remove:\n",
    "            cols_to_remove.add(col)\n",
    "        \n",
    "data = data.drop(columns = list(cols_to_remove))\n",
    "\n",
    "y = data.pop(\"'Diabetes category'\").values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "data[\"'Diabetes category'\"] = y\n",
    "\n",
    "data = data[(np.abs(stats.zscore(data)) < 3).all(axis=1)]\n",
    "\n",
    "y = data.pop(\"'Diabetes category'\")\n",
    "\n",
    "\n",
    "# transform target class to integer\n",
    "\n",
    "\n",
    "X = data.values\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting to visualize distribution\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "x = ['Low 1', 'Medium 2', 'High 0']\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "derp = dict(zip(unique, counts))\n",
    "energy = [80, 302, 118]\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(x)]\n",
    "\n",
    "plt.bar(x_pos, energy, color='green')\n",
    "plt.xlabel(\"Diabetes\")\n",
    "plt.ylabel(\"Number of entries\")\n",
    "plt.title(\"Derp\")\n",
    "\n",
    "plt.xticks(x_pos, x)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so I normalise everything, and then perform k-fold cross validation to select a model to use.\n",
    "# Then after I select a model, I will perform a training_test_split to find the actual accuracy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.40, shuffle=True, random_state=42, stratify=y)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalised_X = scaler.fit_transform(X_train)\n",
    "normalised_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting ranking of features using info-gain\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, f_classif\n",
    "\n",
    "i_scores = mutual_info_classif(normalised_X, y_train)\n",
    "X_train_df = pd.DataFrame(data=normalised_X, columns=list(data.columns))\n",
    "\n",
    "df = pd.DataFrame(i_scores, index = X_train_df\n",
    "                  .columns, columns=['I-Gain'])\n",
    "df.loc[df['I-Gain'].duplicated(), 'I-Gain'] = 0\n",
    "df.sort_values(by=['I-Gain'], ascending=False,inplace=True)\n",
    "df.head(n=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "\n",
    "best_n_features = 1\n",
    "best_acc = 0\n",
    "best_k = 1\n",
    "best_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Finding the best parameters by looping through each k in 1 to 10, and doing cross_val with each subset of features\n",
    "# up to all features.\n",
    "# Best parameters are saved\n",
    "\n",
    "for k in range(1, 10):\n",
    "    scores = []\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    for up_to_index_feature in range(1, len(df.index) + 1):\n",
    "        selected_features = X_train_df[df.index[:up_to_index_feature]]\n",
    "        top_selected_features = selected_features.values\n",
    "        curr_acc = cross_val_score(model, top_selected_features, y_train, cv=10, scoring='f1_macro')[0]\n",
    "\n",
    "        scores.append(curr_acc)\n",
    "\n",
    "        if (curr_acc > best_acc):\n",
    "            best_acc = curr_acc\n",
    "            best_n_features = up_to_index_feature\n",
    "            best_k = k\n",
    "            best_score = scores\n",
    "            \n",
    "    plt.plot(scores)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('top n features')\n",
    "    plt.show()\n",
    "        \n",
    "df.head(n=best_n_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean Acc:\\n{}\".format(np.mean(best_score)))\n",
    "print(\"\\nBest N Features:\\n{}\".format(best_n_features))\n",
    "print(\"\\nBest Acc:\\n{}\".format(best_acc))\n",
    "print(\"\\nBest K:\\n{}\".format(best_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_test_X = scaler.fit_transform(X_test)\n",
    "normalised_test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the performance of the model using SelectKBest to select the best parameters\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "selection = SelectKBest(score_func=mutual_info_classif, k=best_n_features).fit(normalised_X, y_train)\n",
    "X_features = selection.transform(normalised_X)\n",
    "print(X_features.shape)\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "model.fit(X_features, y_train)\n",
    "\n",
    "X_test_features = selection.transform(normalised_test_X)\n",
    "y_pred = model.predict(X_test_features)\n",
    "\n",
    "matrix = classification_report(y_test, y_pred, labels=[0, 1, 2])\n",
    "print('Classification report : \\n',matrix)\n",
    "\n",
    "print(\"Accuracy:\\n{}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "plot_confusion_matrix(model, X_test_features, y_test)\n",
    "confusion = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "print(\"\\nConfusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1(a) - Wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFS k-NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finding the best parameters by looping through each k in 1 to 10, and doing cross_val with each subset of features\n",
    "# up to all features.\n",
    "# Best parameters are saved\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.40, shuffle=True, random_state=42, stratify=y)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalised_X = scaler.fit_transform(X_train)\n",
    "normalised_X.shape\n",
    "\n",
    "normalised_X_test = scaler.fit_transform(X_test)\n",
    "normalised_X_test.shape\n",
    "\n",
    "best_acc = 0\n",
    "best_k = 1; \n",
    "best_feat_index = []\n",
    "best_feat_names = []\n",
    "best_sfs = 0\n",
    "\n",
    "for k in range(1, 10):\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "\n",
    "    sfs_forward = SFS(knn, \n",
    "                  k_features=(1, len(X[1])),\n",
    "                  forward=True, \n",
    "                  floating=False, \n",
    "                  verbose=1, \n",
    "                  scoring='f1_macro',\n",
    "                  cv=10, \n",
    "                  n_jobs=-1)\n",
    "\n",
    "\n",
    "    sfs_forward = sfs_forward.fit(normalised_X, y_train, custom_feature_names=data.columns)\n",
    "\n",
    "    print('best combination (ACC: %.3f): %s\\n' % (sfs_forward.k_score_, sfs_forward.k_feature_idx_))\n",
    "    \n",
    "    if sfs_forward.k_score_ > best_acc:\n",
    "        best_acc = sfs_forward.k_score_\n",
    "        best_k = k\n",
    "        best_feat_index = sfs_forward.k_feature_idx_\n",
    "        best_feat_names = sfs_forward.k_feature_names_\n",
    "        best_sfs = sfs_forward\n",
    "\n",
    "print('\\n\\nBest acc : \\n',best_acc)\n",
    "print('\\n\\nBest k : \\n',best_k)\n",
    "       \n",
    "# Plotting chart for the best SFS\n",
    "figl = plot_sfs(best_sfs.get_metric_dict(), ylabel='Accuracy', kind='std_dev')\n",
    "\n",
    "plt.ylim([0.5, 1])\n",
    "plt.title('Sequential Forward Selection (w. StdDev)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print(\"Features:\")\n",
    "for feat in best_sfs.k_feature_names_:\n",
    "    print(feat)\n",
    "\n",
    "# Testing the performance of the model using SelectKBest to select the best parameters\n",
    "X_train_sfs = best_sfs.transform(normalised_X)\n",
    "X_test_sfs = best_sfs.transform(normalised_X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = best_k)\n",
    "\n",
    "knn.fit(X_train_sfs, y_train)\n",
    "y_pred = knn.predict(X_test_sfs)\n",
    "\n",
    "matrix = classification_report(y_test, y_pred,labels=[0, 1, 2])\n",
    "print('Classification report : \\n',matrix)\n",
    "\n",
    "print(\"\\nModel Prediction Accuracy:\\n{}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "print(\"\\nConfusion matrix:\\n{}\".format(confusion))\n",
    "\n",
    "transformed_y = []\n",
    "\n",
    "for target_y in y:\n",
    "    if target_y == 0:\n",
    "        transformed_y.append(1)\n",
    "    else:\n",
    "        transformed_y.append(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, transformed_y, test_size=0.40, shuffle=True, random_state=1, stratify=y)\n",
    "\n",
    "y_score = knn.predict_proba(X_test_sfs)\n",
    "fprN, tprN, t = roc_curve(y_test, y_score[:,0])\n",
    "roc_aucN = auc(fprN, tprN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFS GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "sfs_forward = SFS(gnb, \n",
    "              k_features=(1, len(X[1])),\n",
    "              forward=True, \n",
    "              floating=False, \n",
    "              verbose=1, \n",
    "              scoring='f1_macro',\n",
    "              cv=10, \n",
    "              n_jobs=-1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, shuffle=True, random_state=1, stratify=y)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalised_X = scaler.fit_transform(X_train)\n",
    "normalised_X.shape\n",
    "\n",
    "normalised_X_test = scaler.fit_transform(X_test)\n",
    "normalised_X_test.shape\n",
    "\n",
    "# Plotting SFS\n",
    "sfs_forward = sfs_forward.fit(normalised_X, y_train, custom_feature_names=data.columns)\n",
    "figl = plot_sfs(sfs_forward.get_metric_dict(), ylabel='Accuracy', kind='std_dev')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.title('Sequential Forward Selection (w. StdDev)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print('best combination (ACC: %.3f): %s\\n' % (sfs_forward.k_score_, sfs_forward.k_feature_idx_))\n",
    "\n",
    "print(\"Features:\")\n",
    "for feat in sfs_forward.k_feature_names_:\n",
    "    print(feat)\n",
    "    \n",
    "# Testing the performance of the model using SelectKBest to select the best parameters\n",
    "X_train_sfs = best_sfs.transform(normalised_X)\n",
    "X_test_sfs = best_sfs.transform(normalised_X_test)\n",
    "\n",
    "gnb.fit(X_train_sfs, y_train)\n",
    "y_pred = gnb.predict(X_test_sfs)\n",
    "\n",
    "# Printing evaluation\n",
    "matrix = classification_report(y_test, y_pred,labels=[0, 1, 2])\n",
    "print('Classification report : \\n',matrix)\n",
    "\n",
    "print(\"\\nModel Prediction Accuracy:\\n{}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "print(\"\\nConfusion matrix:\\n{}\".format(confusion))\n",
    "\n",
    "# transformed_y = []\n",
    "\n",
    "# for target_y in y:\n",
    "#     if target_y == 0:\n",
    "#         transformed_y.append(1)\n",
    "#     else:\n",
    "#         transformed_y.append(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, transformed_y, test_size=1/3, shuffle=True, random_state=1, stratify=y)\n",
    "\n",
    "y_score = gnb.predict_proba(X_test_sfs)\n",
    "fprG, tprG, t = roc_curve(y_test, y_score[:,0])\n",
    "roc_aucG = auc(fprG, tprG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFS Decision Tree Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "# for k in range(1, len(X[1]) + 1):\n",
    "sfs_forward = SFS(tree, \n",
    "              k_features=(1, len(X[1])),\n",
    "              forward=True, \n",
    "              floating=False, \n",
    "              verbose=1, \n",
    "              scoring='f1_macro',\n",
    "              cv=10, \n",
    "              n_jobs=-1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, shuffle=True, random_state=1, stratify=y)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalised_X = scaler.fit_transform(X_train)\n",
    "normalised_X.shape\n",
    "\n",
    "normalised_X_test = scaler.fit_transform(X_test)\n",
    "normalised_X_test.shape\n",
    "\n",
    "# Plotting SFS\n",
    "sfs_forward = sfs_forward.fit(normalised_X, y_train, custom_feature_names=data.columns)\n",
    "figl = plot_sfs(sfs_forward.get_metric_dict(), ylabel='Accuracy', kind='std_dev')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.title('Sequential Forward Selection (w. StdDev)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print('best combination (ACC: %.3f): %s\\n' % (sfs_forward.k_score_, sfs_forward.k_feature_idx_))\n",
    "\n",
    "print(\"Features:\")\n",
    "for feat in sfs_forward.k_feature_names_:\n",
    "    print(feat)\n",
    "\n",
    "\n",
    "# Testing the performance of the model using SelectKBest to select the best parameters\n",
    "X_train_sfs = best_sfs.transform(normalised_X)\n",
    "X_test_sfs = best_sfs.transform(normalised_X_test)\n",
    "\n",
    "tree.fit(X_train_sfs, y_train)\n",
    "y_pred = tree.predict(X_test_sfs)\n",
    "\n",
    "# Printing evaluation\n",
    "matrix = classification_report(y_test, y_pred,labels=[0, 1, 2])\n",
    "print('Classification report : \\n',matrix)\n",
    "\n",
    "print(\"\\nModel Prediction Accuracy:\\n{}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "print(\"\\nConfusion matrix:\\n{}\".format(confusion))\n",
    "\n",
    "# transformed_y = []\n",
    "\n",
    "# for target_y in y:\n",
    "#     if target_y == 0:\n",
    "#         transformed_y.append(1)\n",
    "#     else:\n",
    "#         transformed_y.append(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, transformed_y, test_size=0.35, shuffle=True, random_state=1, stratify=y)\n",
    "\n",
    "y_score = tree.predict_proba(X_test_sfs)\n",
    "fprT, tprT, t = roc_curve(y_test, y_score[:,0])\n",
    "roc_aucT = auc(fprT, tprT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "# for k in range(1, len(X[1]) + 1):\n",
    "sfs_forward = SFS(tree, \n",
    "              k_features=(1, len(X[1])),\n",
    "              forward=True, \n",
    "              floating=False, \n",
    "              verbose=1, \n",
    "              scoring='f1_macro',\n",
    "              cv=10, \n",
    "              n_jobs=-1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, shuffle=True, random_state=1, stratify=y)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "normalised_X = scaler.fit_transform(X_train)\n",
    "normalised_X.shape\n",
    "\n",
    "normalised_X_test = scaler.fit_transform(X_test)\n",
    "normalised_X_test.shape\n",
    "\n",
    "# Testing the performance of the model using SelectKBest to select the best parameters\n",
    "sfs_forward = sfs_forward.fit(normalised_X, y_train, custom_feature_names=data.columns)\n",
    "figl = plot_sfs(sfs_forward.get_metric_dict(), ylabel='Accuracy', kind='std_dev')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.title('Sequential Forward Selection (w. StdDev)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print('best combination (ACC: %.3f): %s\\n' % (sfs_forward.k_score_, sfs_forward.k_feature_idx_))\n",
    "\n",
    "print(\"Features:\")\n",
    "for feat in sfs_forward.k_feature_names_:\n",
    "    print(feat)\n",
    "  \n",
    "\n",
    "    # Testing the performance of the model using SelectKBest to select the best parameters\n",
    "X_train_sfs = best_sfs.transform(normalised_X)\n",
    "X_test_sfs = best_sfs.transform(normalised_X_test)\n",
    "\n",
    "tree.fit(X_train_sfs, y_train)\n",
    "y_pred = tree.predict(X_test_sfs)\n",
    "\n",
    "matrix = classification_report(y_test, y_pred,labels=[0, 1, 2])\n",
    "print('Classification report : \\n',matrix)\n",
    "\n",
    "print(\"\\nModel Prediction Accuracy:\\n{}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "confusion = confusion_matrix(y_test, y_pred, labels=[0, 1, 2])\n",
    "print(\"\\nConfusion matrix:\\n{}\".format(confusion))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 if high, 0 if low or medium. This is due to ROC being a binary classifier\n",
    "# transformed_y = []\n",
    "\n",
    "# for target_y in y:\n",
    "#     if target_y == 0:\n",
    "#         transformed_y.append(1)\n",
    "#     else:\n",
    "#         transformed_y.append(0)\n",
    "        \n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, transformed_y, test_size=.35, shuffle=True, random_state=1)\n",
    "\n",
    "# knn.fit(X_train, y_train)\n",
    "# y_score = knn.predict_proba(X_test)\n",
    "# fprN, tprN, t = roc_curve(y_test, y_score[:,1])\n",
    "# roc_aucN = auc(fprN, tprN)\n",
    "\n",
    "# gnb.fit(X_train, y_train)\n",
    "# y_score = gnb.predict_proba(X_test)\n",
    "# fprG, tprG, t = roc_curve(y_test, y_score[:,1])\n",
    "# roc_aucG = auc(fprG, tprG)\n",
    "\n",
    "# tree.fit(X_train, y_train)\n",
    "# y_score = tree.predict_proba(X_test)\n",
    "# fprT, tprT, t = roc_curve(y_test, y_score[:,1])\n",
    "# roc_aucT = auc(fprT, tprT)\n",
    "\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fprG, tprG, color='blue', lw=lw, label='GNB, Area = %0.2f'% roc_aucG)\n",
    "plt.plot(fprN, tprN, color='green', lw=lw, label='kNN, Area = %0.2f'% roc_aucN)\n",
    "plt.plot(fprT, tprT, color='red', lw=lw, label='DTC, Area = %0.2f'% roc_aucT)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
