{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "from linecache import getline\n",
    "from gurobipy import Model, GRB, quicksum\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileParser:\n",
    "#     def __init__(self):\n",
    "        \n",
    "    def parseCoords(line):\n",
    "        x = line.split()\n",
    "        return [x[0], x[1], x[2]]\n",
    "\n",
    "    def parseDemand(line):\n",
    "        x = line.split()\n",
    "        return [int(x[0]), int(x[1])]\n",
    "\n",
    "    def parseRoutes(line):\n",
    "        x = line.split()\n",
    "        parsedRoutes = x[2:]\n",
    "        parsedRoutes.insert(0, \"1\")\n",
    "\n",
    "        return parsedRoutes\n",
    "\n",
    "    def readInstance(file):\n",
    "        COORD_FLAG = False\n",
    "        DEMAND_FLAG = False\n",
    "\n",
    "        xc, yc = [], []\n",
    "        coords, q = {}, {}\n",
    "\n",
    "        fh = open(file, 'r')\n",
    "        for i, line in enumerate(fh):\n",
    "            if \"NODE_COORD_SECTION\" in line:\n",
    "                COORD_FLAG = True\n",
    "            elif \"DEMAND_SECTION\" in line:\n",
    "                COORD_FLAG = False\n",
    "                DEMAND_FLAG = True\n",
    "            elif \"DEPOT_SECTION\" in line:\n",
    "                DEMAND_FLAG = False\n",
    "            elif COORD_FLAG:\n",
    "                coord = parseCoords(line)\n",
    "                xc.append(coord[1])\n",
    "                yc.append(coord[2])\n",
    "                coords[coord[0]] = [coord[1], coord[2]]\n",
    "            elif DEMAND_FLAG:\n",
    "                demand = parseDemand(line)\n",
    "                q[demand[0]] = demand[1]\n",
    "        fh.close()\n",
    "\n",
    "        return xc, yc, coords, q\n",
    "\n",
    "\n",
    "    def readSolution(file):\n",
    "        fh = open(file, 'r')  # A-n32-k5-solution.txt\n",
    "        routes = {}\n",
    "        for i, line in enumerate(fh):\n",
    "            if \"Route #\" in line:\n",
    "                routes[i] = parseRoutes(line)\n",
    "                routes[i] = [x for x in routes[i] ]\n",
    "                routes[i].append(\"1\")\n",
    "        return routes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading text files containing instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "readInstance() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2b8e4aceab3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfileParser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFileParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mxc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfileParser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadInstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../Instances/Instances/A-n32-k5.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: readInstance() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "fileParser = FileParser()\n",
    "xc, yc, coords, q = fileParser.readInstance(\"../Instances/Instances/A-n32-k5.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_set = set()\n",
    "\n",
    "def compareCoordID(u, v):\n",
    "    return u == v\n",
    "\n",
    "def checkEdgeExists(tempSet, str1, str2):\n",
    "    return str1 in tempSet or str2 in tempSet\n",
    "\n",
    "def stringEdgeBuilder(u, v):\n",
    "    return \"(\" + u + \", \" + v + \")\"\n",
    "\n",
    "def createEdgeStrings(u, v):\n",
    "    return stringEdgeBuilder(u, v), stringEdgeBuilder(v, u)\n",
    "\n",
    "def calculateWeight(coord_u, coord_v):\n",
    "    return np.hypot(int(coord_u[0]) - int(coord_v[0]), int(coord_u[1]) - int(coord_v[1]))\n",
    "\n",
    "def getEdgesInOptimalRoute(routes):\n",
    "    edges_in_optimal_route = set()\n",
    "    \n",
    "    for route in routes:\n",
    "        curr = routes[route]\n",
    "\n",
    "        for index in range(0, len(curr) - 1):\n",
    "            coordStr1, coordStr2 = createEdgeStrings(curr[index], curr[index + 1])\n",
    "\n",
    "            if not checkEdgeExists(edges_in_optimal_route, coordStr1, coordStr2):\n",
    "                edges_in_optimal_route.add(coordStr1)\n",
    "    return edges_in_optimal_route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes = fileParser.readSolution(\"../Instances/Solutions/test.txt\")\n",
    "    \n",
    "edges_in_optimal_route = getEdgesInOptimalRoute(routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initIncidentMatrix(matrix_size):\n",
    "    return np.zeros((matrix_size, matrix_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = initIncidentMatrix(len(coords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEdgesDict(coords):\n",
    "    edges = defaultdict(list)\n",
    "    dict_global_edge_rank = {}\n",
    "    index, row, column = 0, 0, 0\n",
    "\n",
    "    for u in coords:\n",
    "        for v in coords:\n",
    "            coordStr1 = stringEdgeBuilder(u, v)\n",
    "            coordStr2 = stringEdgeBuilder(v, u)\n",
    "\n",
    "            coord_u = coords[u]\n",
    "            coord_v = coords[v]\n",
    "            edge_weight = calculateWeight(coord_u, coord_v)\n",
    "\n",
    "            if not compareCoordID(u, v) and not checkEdgeExists(edges_set, coordStr1, coordStr2):\n",
    "                edges_set.add(coordStr1)\n",
    "\n",
    "                edges[\"U_X\"].append(coord_u[0])\n",
    "                edges[\"U_Y\"].append(coord_u[1])\n",
    "                edges[\"U_NODE_ID\"].append(u)\n",
    "\n",
    "                edges[\"V_X\"].append(coord_v[0])\n",
    "                edges[\"V_ Y\"].append(coord_v[1])\n",
    "                edges[\"V_NODE_ID\"].append(v)\n",
    "\n",
    "\n",
    "                edges[\"EDGE_WEIGHT\"].append(edge_weight)\n",
    "                dict_global_edge_rank[index] = edge_weight\n",
    "                index += 1\n",
    "\n",
    "                if checkEdgeExists(edges_in_optimal_route, coordStr1, coordStr2):\n",
    "                    edges[\"IS_OPTIMAL_EDGE\"].append(1)\n",
    "                else:\n",
    "                    edges[\"IS_OPTIMAL_EDGE\"].append(0)\n",
    "\n",
    "            arr[row][column] = edge_weight\n",
    "            column += 1\n",
    "        column = 0\n",
    "        row += 1\n",
    "        \n",
    "    return edges, dict_global_edge_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edges, dict_global_edge_rank = createEdgesDict(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelMatrix(coords, arr):\n",
    "    row_labels = [row for row in coords]\n",
    "    column_labels = [col for col in coords]\n",
    "    incidence_matrix = pd.DataFrame(arr, columns=column_labels, index=row_labels)\n",
    "    \n",
    "    return incidence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incidence_matrix = labelMatrix(coords, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfFactory(edges):\n",
    "    return pd.DataFrame(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfFactory(edges)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [16,9]\n",
    "\n",
    "graph = df[['U_NODE_ID', 'V_NODE_ID']].where(df['IS_OPTIMAL_EDGE'] == 1)\n",
    "graph\n",
    " \n",
    "G = nx.from_pandas_edgelist(graph, 'U_NODE_ID', 'V_NODE_ID')\n",
    "\n",
    "nx.draw(G, with_labels=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateLocalRank(u, v):\n",
    "    row = incidence_matrix[u]\n",
    "    sorted_row = row.sort_values(ascending=True)\n",
    "    return sorted_row[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Degree:\n",
    "    def __init__(self, G):\n",
    "        self.degrees = G.degree\n",
    "        self.u_node_degree = []\n",
    "        self.v_node_degree = []\n",
    "        self.node_average_degree = []\n",
    "        \n",
    "    def addDegrees(self, node_u, node_v):\n",
    "        self.addUDegree(node_u)\n",
    "        self.addVDegree(node_v)\n",
    "        self.addAverageDegree(node_u, node_v)\n",
    "        \n",
    "    def addUDegree(self, nodeID):\n",
    "        self.u_node_degree.append(self.degrees[nodeID])\n",
    "        \n",
    "    def addVDegree(self, nodeID):\n",
    "        self.v_node_degree.append(self.degrees[nodeID])\n",
    "        \n",
    "    def addAverageDegree(self, node_u, node_v):\n",
    "        self.node_average_degree.append((self.degrees[node_u] + self.degrees[node_v]) / 2)\n",
    "        \n",
    "    def getNodeDegree(self, nodeID):\n",
    "        return self.degrees[nodeID]\n",
    "    \n",
    "    def getAverageNodeDegree(self, node_u, node_v):\n",
    "        return (self.degrees[node_u] + self.degrees[node_v]) / 2\n",
    "    \n",
    "    def addToDF(self, df):\n",
    "#         u_node_dict = {'U_NODE_DEGREE': self.u_node_degree}\n",
    "#         df = df.append(pd.DataFrame(u_node_dict))\n",
    "        df = df.append(pd.DataFrame(data=u_node_degree, columns=['U_NODE_DEGREE']))\n",
    "        \n",
    "        print(df)\n",
    "        \n",
    "        v_node_dict = {'V_NODE_DEGREE': self.v_node_degree}\n",
    "        df = df.append(pd.DataFrame(v_node_dict))\n",
    "        \n",
    "        print(df)\n",
    "        \n",
    "        node_average_dict = {'AVERAGE_NODE_DEGREE': self.node_average_degree}\n",
    "        df = df.append(pd.DataFrame(node_average_dict))\n",
    "    \n",
    "        print(df)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EigenvectorCentrality:\n",
    "    def __init__(self):\n",
    "        self.u_node_eigenvector_centrality = []\n",
    "        self.v_node_eigenvector_centrality = []\n",
    "        self.average_eigenvector_centrality = []\n",
    "        \n",
    "    def addUEigenvectorCentrality(eigenvectorCentrality):\n",
    "        self.u_node_clustering.append(eigenvectorCentrality)\n",
    "        \n",
    "    def addVEigenvectorCentrality(eigenvectorCentrality):\n",
    "        self.v_node_clustering.append(eigenvectorCentrality)\n",
    "        \n",
    "    def addAverageEigenvectorCentrality(eigenvectorCentrality):\n",
    "        self.average_node_clustering.append(eigenvectorCentrality)\n",
    "        \n",
    "    def getEigenvectorCentrality(G):\n",
    "        return nx.eigenvector_centrality(G)\n",
    "    \n",
    "    def addToDF(df):\n",
    "        df['U_NODE_EIGENVECTOR_CENTRALITY'] = u_node_eigenvector_centrality\n",
    "        df['V_NODE_EIGENVECTOR_CENTRALITY'] = v_node_eigenvector_centrality\n",
    "        df['AVERAGE_NODE_EIGENVECTOR_CENTRALITY'] = average_eigenvector_centrality\n",
    "    \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clustering:\n",
    "    def __init__(self, G):\n",
    "        self.clustering = nx.clustering(G)\n",
    "        self.u_node_clustering = []\n",
    "        self.v_node_clustering = []\n",
    "        self.average_node_clustering = []\n",
    "    \n",
    "    def addClusterings(self, node_u, node_v):\n",
    "        self.addUClustering(node_u)\n",
    "        self.addVClustering(node_v)\n",
    "        self.addAverageClustering(node_u, node_v)        \n",
    "        \n",
    "    def addUClustering(self, nodeID):\n",
    "        self.u_node_clustering.append(self.clustering[nodeID])\n",
    "        \n",
    "    def addVClustering(self, nodeID):\n",
    "        self.v_node_clustering.append(self.clustering[nodeID])\n",
    "        \n",
    "    def addAverageClustering(self, node_u, node_v):\n",
    "        self.average_node_clustering.append((self.clustering[node_u] + self.clustering[node_v]) / 2)\n",
    "        \n",
    "    def getClustering():\n",
    "        return self.clustering\n",
    "    \n",
    "    def addToDF(self, df):\n",
    "        u_node_dict = {'U_NODE_CLUSTERING': self.u_node_clustering}\n",
    "        df = df.append(pd.DataFrame(u_node_dict))\n",
    "        \n",
    "        v_node_dict = {'V_NODE_CLUSTERING': self.v_node_clustering}\n",
    "        df = df.append(pd.DataFrame(v_node_dict))\n",
    "        \n",
    "        node_average_dict = {'AVERAGE_NODE_CLUSTERING': self.average_node_clustering}\n",
    "        df = df.append(pd.DataFrame(node_average_dict))\n",
    "    \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DegreeCentrality:\n",
    "    def __init__(self):\n",
    "        self.u_node_degree_centrality = []\n",
    "        self.v_node_degree_centrality = []\n",
    "        self.average_degree_centrality = []\n",
    "        \n",
    "    def addUDegreeCentrality(degreeCentrality):\n",
    "        self.u_node_degree_centrality.append(degreeCentrality)\n",
    "        \n",
    "    def addVDegreeCentrality(degreeCentrality):\n",
    "        self.v_node_degree_centrality.append(degreeCentrality)\n",
    "        \n",
    "    def addAverageDegreeCentrality(degreeCentrality):\n",
    "        self.average_degree_centrality.append(degreeCentrality)\n",
    "        \n",
    "    def getClustering(G):\n",
    "        return nx.clustering(G)\n",
    "    \n",
    "    def addToDF(df):\n",
    "        df['U_NODE_DEGREE_CENTRALITY'] = u_node_degree_centrality\n",
    "        df['V_NODE_DEGREE_CENTRALITY'] = u_node_degree_centrality\n",
    "        df['AVERAGE_NODE_DEGREE_CENTRALITY'] = average_degree_centrality\n",
    "    \n",
    "        return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature flags\n",
    "\n",
    "degreeFlag = True\n",
    "# eigenvector_centrality = True\n",
    "clusteringFlag = True\n",
    "# degree_centrality = True\n",
    "global_rank = True\n",
    "local_rank = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_node_degree = []\n",
    "v_node_degree = []\n",
    "node_average_degree = []\n",
    "\n",
    "global_edge_rank = []\n",
    "\n",
    "u_node_local_edge_rank = []\n",
    "v_node_local_edge_rank = []\n",
    "\n",
    "# u_node_eigenvector_centrality = []\n",
    "# v_node_eigenvector_centrality = []\n",
    "# average_eigenvector_centrality = []\n",
    "\n",
    "u_node_clustering = []\n",
    "v_node_clustering = []\n",
    "average_node_clustering = []\n",
    "\n",
    "# u_node_degree_centrality = []\n",
    "# v_node_degree_centrality = []\n",
    "# average_degree_centrality = []\n",
    "\n",
    "# if eigenvector_centrality:\n",
    "#     eigenvector_centrality = nx.eigenvector_centrality(G)\n",
    "\n",
    "# if clustering:\n",
    "#     clustering = nx.clustering(G)\n",
    "\n",
    "# if degree_centrality:\n",
    "#     degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "degree = Degree(G)\n",
    "clustering = Clustering(G)\n",
    "    \n",
    "for index, row in df.iterrows():\n",
    "    if degreeFlag:\n",
    "        node_u, node_v = row[\"U_NODE_ID\"], row[\"V_NODE_ID\"]\n",
    "        degree.addDegrees(node_u, node_v)\n",
    "    \n",
    "#     if eigenvector_centrality:\n",
    "#         node_u = eigenvector_centrality[row[\"U_NODE_ID\"]]\n",
    "#         u_node_eigenvector_centrality.append(node_u)\n",
    "        \n",
    "#         node_v = eigenvector_centrality[row[\"V_NODE_ID\"]]\n",
    "#         v_node_eigenvector_centrality.append(node_v)\n",
    "        \n",
    "#         average_eigenvector_centrality.append((node_u + node_v) / 2)\n",
    "\n",
    "    if clusteringFlag:\n",
    "        node_u, node_v = row[\"U_NODE_ID\"], row[\"V_NODE_ID\"]\n",
    "        clustering.addClusterings(node_u, node_v)\n",
    "    \n",
    "#     if degree_centrality:\n",
    "#         node_u = degree_centrality[row[\"U_NODE_ID\"]]\n",
    "#         u_node_degree_centrality.append(node_u)\n",
    "        \n",
    "#         node_v = degree_centrality[row[\"V_NODE_ID\"]]\n",
    "#         v_node_degree_centrality.append(node_v)\n",
    "        \n",
    "#         average_degree_centrality.append((node_u + node_v) / 2)\n",
    "        \n",
    "    if global_rank:\n",
    "        global_edge_rank.append(dict_global_edge_rank[index])\n",
    "    \n",
    "    if local_rank:\n",
    "        u_node_local_edge_rank.append(calculateLocalRank(row[\"U_NODE_ID\"], row[\"V_NODE_ID\"]))\n",
    "        v_node_local_edge_rank.append(calculateLocalRank(row[\"V_NODE_ID\"], row[\"U_NODE_ID\"]))\n",
    "\n",
    "if degreeFlag:\n",
    "    df = degree.addToDF(df)\n",
    "\n",
    "# if eigenvector_centrality:\n",
    "#     df['U_NODE_EIGENVECTOR_CENTRALITY'] = u_node_eigenvector_centrality\n",
    "#     df['V_NODE_EIGENVECTOR_CENTRALITY'] = v_node_eigenvector_centrality\n",
    "#     df['AVERAGE_NODE_EIGENVECTOR_CENTRALITY'] = average_eigenvector_centrality\n",
    "\n",
    "if clusteringFlag:\n",
    "    df = clustering.addToDF(df)\n",
    "#     df['U_NODE_CLUSTERING'] = u_node_clustering\n",
    "#     df['V_NODE_CLUSTERING'] = v_node_clustering\n",
    "#     df['AVERAGE_NODE_CLUSTERING'] = average_node_clustering\n",
    "\n",
    "# if degree_centrality:\n",
    "#     df['U_NODE_DEGREE_CENTRALITY'] = u_node_degree_centrality\n",
    "#     df['V_NODE_DEGREE_CENTRALITY'] = u_node_degree_centrality\n",
    "#     df['AVERAGE_NODE_DEGREE_CENTRALITY'] = average_degree_centrality\n",
    "    \n",
    "# if global_rank:\n",
    "#     df['GLOBAL_EDGE_RANK'] = global_edge_rank\n",
    "\n",
    "# if local_rank:\n",
    "#     df['U_NODE_LOCAL_EDGE_RANK'] = u_node_local_edge_rank\n",
    "#     df['V_NODE_LOCAL_EDGE_RANK'] = v_node_local_edge_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['GLOBAL_EDGE_RANK'] == '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
